{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff'\n",
    "task = 'EvaluatePrequentialRegression'\n",
    "learner = 'BufferLearner'\n",
    "arf_k = 14\n",
    "# buffer_learner = f'(meta.AdaptiveRandomForestRegressor -l (ARFFIMTDD -k {arf_k} -s VarianceReductionSplitCriterion -g 50 -c 0.01) -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'(meta.AdaptiveRandomForestRegressor -l (ARFFIMTDD -k {arf_k} -s VarianceReductionSplitCriterion -g 50 -c 0.01) -m 80 -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "stream = f'(ArffFileStream -f {file})'\n",
    "\n",
    "id_index = 15\n",
    "\n",
    "i = 32000\n",
    "f = 1000\n",
    "q = 1000\n",
    "def generate_command(n, extractor, partition_id, time_ids, cluster_num, buffer_ids, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}vavel_slim_{extractor}_{n}_{cluster_num}_{partition_id}_{time_ids}_{buffer_ids}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p {partition_id} -t {time_ids} -i {id_index} -y {buffer_ids} -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_sizes = [1,5,10,25,50,100]\n",
    "cluster_num = [2,3,4,5,8,25]\n",
    "extractor = ['naive','cluster','featureExtraction', 'cep']\n",
    "vavel_slim_partition_id = [13, 14]\n",
    "time_ids = '0,5,7,9'\n",
    "buffer_ids = ['-1', '4,8', '4,8,12', '1,2,3,4,6,8,11,12']\n",
    "cluster_types = ['clustree', 'clustream']\n",
    "\n",
    "buffer_types = ['random', 'relevance']\n",
    "rs = [0.1, 0.25, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_command(cmd, file_suffix):\n",
    "    file_contents = f'@echo off\\n\\\n",
    "    \\n\\\n",
    "    set BASEDIR=%~dp0\\..\\n\\\n",
    "    set MEMORY=6g\\n\\\n",
    "    \\n\\\n",
    "    java -Xmx%MEMORY% -cp \"%BASEDIR%/lib/*\" -javaagent:\"%BASEDIR%/lib/sizeofag-1.0.4.jar\" ^\\n\\\n",
    "    moa.DoTask ^\\n\\\n",
    "    \"{cmd} \"'\n",
    "    filename = r'..\\moa-release-2020.07.1\\bin\\moa_test_run_' + file_suffix + '.bat'\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(file_contents)\n",
    "    out = subprocess.Popen(filename)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n",
      "Running with n = 50\n",
      "Running with n = 100\n"
     ]
    }
   ],
   "source": [
    "outs = []\n",
    "for n in buffer_sizes:\n",
    "    cmd = generate_command(n, 'cluster', 14, time_ids, 8, '-1', target_dir = '20210613/cluster/n/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "for n in [1,3,5,10]:\n",
    "    cmd = generate_command(n, 'naive', 14, time_ids, 25, '4,8,12', target_dir = '20210613/naive/n/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'naive_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n",
      "Running with n = 50\n",
      "Running with n = 100\n"
     ]
    }
   ],
   "source": [
    "for n in buffer_sizes[1:]:\n",
    "    cmd = generate_command(n, 'cep', 14, time_ids, 6, '-1', target_dir = '20210613/cep/n/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'cep_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n"
     ]
    }
   ],
   "source": [
    "for n in [1,3,5,10,25]:\n",
    "    cmd = generate_command(n, 'featureExtraction', 14, time_ids, 25, '-1', target_dir = '20210613/extract/n/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'extract_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [5,10,25]:\n",
    "    cmd = generate_command(n, 'featureExtraction', 14, time_ids, 25, '-1', target_dir = '20210613/extract/n/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'extract_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 2\n",
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 5\n",
      "Running with c = 25\n"
     ]
    }
   ],
   "source": [
    "for c in cluster_num:\n",
    "    if c != 8:\n",
    "        cmd = generate_command(25, 'cluster', 14, time_ids, c, '-1', target_dir = '20210613/cluster/c/')\n",
    "        print(f\"Running with c = {c}\")\n",
    "        out = run_command(cmd,f'c{c}')\n",
    "        outs.append(out)\n",
    "\n",
    "        if len(outs) >= max_together:\n",
    "            outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 10\n",
      "Running with c = 15\n"
     ]
    }
   ],
   "source": [
    "for c in [10,15]:\n",
    "    if c != 8:\n",
    "        cmd = generate_command(25, 'cluster', 14, time_ids, c, '-1', target_dir = '20210613/cluster/c/')\n",
    "        print(f\"Running with c = {c}\")\n",
    "        out = run_command(cmd,f'c{c}')\n",
    "        outs.append(out)\n",
    "\n",
    "        if len(outs) >= max_together:\n",
    "            outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 3\n",
      "Running with c = 5\n",
      "Running with c = 10\n",
      "Running with c = 15\n",
      "Running with c = 25\n"
     ]
    }
   ],
   "source": [
    "clustream_num = [3,5,8,10,15,25]\n",
    "for c in clustream_num:\n",
    "    if c != 8:\n",
    "        cmd = generate_command(25, 'cluster', 14, time_ids, c, '-1', 'clustream', target_dir = '20210613/cluster/c/')\n",
    "        print(f\"Running with c = {c}\")\n",
    "        out = run_command(cmd,f'c{c}')\n",
    "        outs.append(out)\n",
    "\n",
    "        if len(outs) >= max_together:\n",
    "            outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [10,15]:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, c, '-1')\n",
    "    run_command(cmd,f'c{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustream_num = [3,5,8,10,15,25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clustream_num[:2]:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, c, '-1', 'clustream')\n",
    "    run_command(cmd,f'c2{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clustream_num[2:4]:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, c, '-1', 'clustream')\n",
    "    run_command(cmd,f'c2{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in clustream_num[4:]:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, c, '-1', 'clustream')\n",
    "    run_command(cmd,f'c2{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_together = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-1', '4,8', '4,8,12', '1,2,3,4,6,8,11,12']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with b = -1\n",
      "Running with b = 4,8\n",
      "Running with b = 4,8,12\n",
      "Running with b = 1,2,3,4,6,8,11,12\n"
     ]
    }
   ],
   "source": [
    "for b in buffer_ids:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, 25, b)\n",
    "    print(f\"Running with b = {b}\")\n",
    "    out = run_command(cmd,f'b{b.replace(\",\",\"-\")}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n",
      "Running with n = 50\n",
      "Running with n = 100\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 8\n",
      "Running with c = 10\n"
     ]
    }
   ],
   "source": [
    "for c in [3,4,8,10]:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, c, '-1')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'cep_c{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 8\n",
      "Running with c = 10\n"
     ]
    }
   ],
   "source": [
    "for c in [3,4,8,10]:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, c, '-1','clustream')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'cep_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 2\n",
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 5\n",
      "Running with c = 8\n"
     ]
    }
   ],
   "source": [
    "for c in cluster_num[:-1]:\n",
    "    cmd = generate_command(25, 'featureExtraction', 14, time_ids, c, '-1')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'extract_c{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 2\n",
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 5\n",
      "Running with c = 8\n",
      "Running with c = 25\n"
     ]
    }
   ],
   "source": [
    "for c in cluster_num:\n",
    "    cmd = generate_command(25, 'featureExtraction', 14, time_ids, c, '-1', 'clustream')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'extract_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, 25, '-1', r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'r{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(100, 'cluster', 14, time_ids, 25, '-1', buffer_type= 'relevance',r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'r2{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(25, 'featureExtraction', 14, time_ids, 8, '-1', 'clustream', r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'extract_r{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(25, 'featureExtraction', 14, time_ids, 8, '-1', 'clustream', buffer_type='relevance', r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'extract_r2{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 6\n"
     ]
    }
   ],
   "source": [
    "for c in [6]:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, c, '-1','clustream')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'cep_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, 6, '-1','clustream', buffer_type='relevance', r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'cep_r2{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, 6, '-1','clustream', r=r)\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'cep_r{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with p = 13\n"
     ]
    }
   ],
   "source": [
    "for p in [13]:\n",
    "    cmd = generate_command(100, 'cluster', p, time_ids, 25, '-1', buffer_type= 'relevance',r=0.1)\n",
    "    print(f\"Running with p = {p}\")\n",
    "    out = run_command(cmd,f'p{p}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with p = 13\n"
     ]
    }
   ],
   "source": [
    "for p in [13]:\n",
    "    cmd = generate_command(25, 'featureExtraction', p, time_ids, 8, '-1', 'clustream', buffer_type='random', r=0.1)\n",
    "    print(f\"Running with p = {p}\")\n",
    "    out = run_command(cmd,f'extract_p{p}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with p = 13\n"
     ]
    }
   ],
   "source": [
    "for  p in [13]:\n",
    "    cmd = generate_command(25, 'cep', 14, time_ids, 6, '-1','clustree', r=0.5)\n",
    "    print(f\"Running with p = {p}\")\n",
    "    out = run_command(cmd,f'cep_p{p}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r'..\\moa-release-2020.07.1\\bin\\moa_test_run.bat', 'w') as file:\n",
    "    file.write(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = subprocess.Popen(r'..\\moa-release-2020.07.1\\bin\\moa_test_run.bat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_contents = f'@echo off\\n\\\n",
    "\\n\\\n",
    "set BASEDIR=%~dp0\\..\\n\\\n",
    "set MEMORY=6g\\n\\\n",
    "\\n\\\n",
    "java -Xmx%MEMORY% -cp \"%BASEDIR%/lib/*\" -javaagent:\"%BASEDIR%/lib/sizeofag-1.0.4.jar\" ^\\n\\\n",
    "moa.DoTask ^\\n\\\n",
    "\"{cmd} \"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [\n",
    "    'rules.functions.TargetMean',\n",
    "    'rules.functions.FadingTargetMean',\n",
    "    'functions.AdaGrad',\n",
    "    'meta.AdaptiveRandomForestRegressor',\n",
    "    'meta.AdaptiveRandomForestRegressor -m 80',\n",
    "    'rules.AMRulesRegressor',\n",
    "    'rules.functions.Perceptron',\n",
    "    'trees.ARFFIMTDD',\n",
    "\n",
    "]\n",
    "std_set = r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff'\n",
    "slim_set = r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff'\n",
    "\n",
    "\n",
    "std_learn = [f'EvaluatePrequentialRegression -l ({l}) -s (ArffFileStream -f {std_set} ) -i 32000 -f 1000 -q 1000 -d runs/tuning/{l.replace(\" \",\"\")}' for l in learners]\n",
    "slim_learn = [f'EvaluatePrequentialRegression -l ({l}) -s (ArffFileStream -f {slim_set} ) -i 32000 -f 1000 -q 1000 -d runs/tuning/slim_{l.replace(\" \",\"\")}' for l in learners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor-m80']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_learn[4:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.TargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.TargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.FadingTargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.FadingTargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (functions.AdaGrad) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/functions.AdaGrad\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor -m 80\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.meta.RandomAMRules) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.meta.RandomAMRules\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.AMRulesRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.AMRulesRegressor\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in std_learn:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.Perceptron) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.Perceptron\n",
      "Running cmd EvaluatePrequentialRegression -l (trees.ARFFIMTDD) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/trees.ARFFIMTDD\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in std_learn[-2:]:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.TargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.TargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.FadingTargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.FadingTargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (functions.AdaGrad) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/functions.AdaGrad\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor -m 80\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.AMRulesRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.AMRulesRegressor\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.Perceptron) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/rules.functions.Perceptron\n",
      "Running cmd EvaluatePrequentialRegression -l (trees.ARFFIMTDD) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/trees.ARFFIMTDD\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in slim_learn:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/meta.AdaptiveRandomForestRegressor-m80\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in std_learn[4:5]:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\result_sup_slim.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/slim_meta.AdaptiveRandomForestRegressor-m80\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in slim_learn[4:5]:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners_clf = [\n",
    "    'functions.MajorityClass',\n",
    "    'functions.NoChange',\n",
    "    'lazy.SAMkNN',\n",
    "    'bayes.NaiveBayes',\n",
    "    'meta.AdaptiveRandomForest',\n",
    "    'meta.AdaptiveRandomForest -m 80',\n",
    "    'trees.HoeffdingAdaptiveTree',\n",
    "    'meta.OzaBagAdwin',\n",
    "\n",
    "]\n",
    "generated_sets = ['generators.RandomRBFGenerator', 'generators.HyperplaneGenerator','generators.LEDGenerator']\n",
    "\n",
    "index = 0\n",
    "cmds = []\n",
    "for gen_set in generated_sets:\n",
    "    cmds += [f'EvaluatePrequential -l ({l}) -s ({gen_set}) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/{l.replace(\" \",\"\")}_{gen_set}.csv' for l in learners_clf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequential -l (functions.MajorityClass) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.MajorityClass_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (functions.NoChange) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.NoChange_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (lazy.SAMkNN) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/lazy.SAMkNN_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (bayes.NaiveBayes) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/bayes.NaiveBayes_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest -m 80) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest-m80_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (trees.HoeffdingAdaptiveTree) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/trees.HoeffdingAdaptiveTree_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.OzaBagAdwin) -s (generators.RandomRBFGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.OzaBagAdwin_generators.RandomRBFGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (functions.MajorityClass) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.MajorityClass_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (functions.NoChange) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.NoChange_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (lazy.SAMkNN) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/lazy.SAMkNN_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (bayes.NaiveBayes) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/bayes.NaiveBayes_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest -m 80) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest-m80_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (trees.HoeffdingAdaptiveTree) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/trees.HoeffdingAdaptiveTree_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.OzaBagAdwin) -s (generators.HyperplaneGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.OzaBagAdwin_generators.HyperplaneGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (functions.MajorityClass) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.MajorityClass_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (functions.NoChange) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/functions.NoChange_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (lazy.SAMkNN) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/lazy.SAMkNN_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (bayes.NaiveBayes) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/bayes.NaiveBayes_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest -m 80) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.AdaptiveRandomForest-m80_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (trees.HoeffdingAdaptiveTree) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/trees.HoeffdingAdaptiveTree_generators.LEDGenerator.csv\n",
      "Running cmd EvaluatePrequential -l (meta.OzaBagAdwin) -s (generators.LEDGenerator) -i 50000 -f 1000 -q 1000 -d runs/tuning/generator2/meta.OzaBagAdwin_generators.LEDGenerator.csv\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "for cmd in cmds:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'generator_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners_clf = [\n",
    "    'functions.MajorityClass',\n",
    "    'functions.NoChange',\n",
    "    'lazy.SAMkNN',\n",
    "    'bayes.NaiveBayes',\n",
    "    'meta.AdaptiveRandomForest',\n",
    "    'meta.AdaptiveRandomForest -m 80',\n",
    "    'trees.HoeffdingAdaptiveTree',\n",
    "    'meta.OzaBagAdwin',\n",
    "\n",
    "]\n",
    "rest_sets = ['WISDM', 'electricity_arff']\n",
    "\n",
    "index = 0\n",
    "cmds = []\n",
    "wisdm_fullpath =  f'C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\{rest_sets[0]}.arff'\n",
    "electricity_fullpath =  f'C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\{rest_sets[1]}.arff'\n",
    "cmds += [f'EvaluatePrequential -l ({l}) -s (ArffFileStream -f {wisdm_fullpath})-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/{l.replace(\" \",\"\")}_wisdm.csv' for l in learners_clf]\n",
    "# cmds += [f'EvaluatePrequential -l ({l}) -s (ArffFileStream -f {electricity_fullpath}) -i 45000 -f 1000 -q 1000 -d runs/tuning/wisdm/{l.replace(\" \",\"\")}_electricity.csv' for l in learners_clf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EvaluatePrequential -l (functions.MajorityClass) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/functions.MajorityClass_wisdm.csv',\n",
       " 'EvaluatePrequential -l (functions.NoChange) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/functions.NoChange_wisdm.csv',\n",
       " 'EvaluatePrequential -l (lazy.SAMkNN) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/lazy.SAMkNN_wisdm.csv',\n",
       " 'EvaluatePrequential -l (bayes.NaiveBayes) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/bayes.NaiveBayes_wisdm.csv',\n",
       " 'EvaluatePrequential -l (meta.AdaptiveRandomForest) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.AdaptiveRandomForest_wisdm.csv',\n",
       " 'EvaluatePrequential -l (meta.AdaptiveRandomForest -m 80) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.AdaptiveRandomForest-m80_wisdm.csv',\n",
       " 'EvaluatePrequential -l (trees.HoeffdingAdaptiveTree) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/trees.HoeffdingAdaptiveTree_wisdm.csv',\n",
       " 'EvaluatePrequential -l (meta.OzaBagAdwin) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.OzaBagAdwin_wisdm.csv']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequential -l (functions.MajorityClass) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/functions.MajorityClass_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (functions.NoChange) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/functions.NoChange_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (lazy.SAMkNN) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/lazy.SAMkNN_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (bayes.NaiveBayes) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/bayes.NaiveBayes_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.AdaptiveRandomForest_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (meta.AdaptiveRandomForest -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.AdaptiveRandomForest-m80_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (trees.HoeffdingAdaptiveTree) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/trees.HoeffdingAdaptiveTree_wisdm.csv\n",
      "Running cmd EvaluatePrequential -l (meta.OzaBagAdwin) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\WISDM.arff)-e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/meta.OzaBagAdwin_wisdm.csv\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "index = 0\n",
    "for cmd in cmds:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'generator_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [\n",
    "    'rules.functions.TargetMean',\n",
    "    'rules.functions.FadingTargetMean',\n",
    "    'functions.AdaGrad',\n",
    "    'meta.AdaptiveRandomForestRegressor',\n",
    "    'meta.AdaptiveRandomForestRegressor -m 80',\n",
    "    'rules.AMRulesRegressor',\n",
    "    'rules.functions.Perceptron',\n",
    "    'trees.ARFFIMTDD',\n",
    "\n",
    "]\n",
    "air_set = r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff'\n",
    "\n",
    "\n",
    "air_learn = [f'EvaluatePrequentialRegression -l ({l}) -s (ArffFileStream -f {air_set} ) -i 50000 -f 500 -q 500 -d runs/tuning/airlines/{l.replace(\" \",\"\")}' for l in learners]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.TargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/rules.functions.TargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.FadingTargetMean) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/rules.functions.FadingTargetMean\n",
      "Running cmd EvaluatePrequentialRegression -l (functions.AdaGrad) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/functions.AdaGrad\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/meta.AdaptiveRandomForestRegressor\n",
      "Running cmd EvaluatePrequentialRegression -l (meta.AdaptiveRandomForestRegressor -m 80) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/meta.AdaptiveRandomForestRegressor-m80\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.AMRulesRegressor) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/rules.AMRulesRegressor\n",
      "Running cmd EvaluatePrequentialRegression -l (rules.functions.Perceptron) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/rules.functions.Perceptron\n",
      "Running cmd EvaluatePrequentialRegression -l (trees.ARFFIMTDD) -s (ArffFileStream -f C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/trees.ARFFIMTDD\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "max_together = 3\n",
    "for cmd in air_learn:\n",
    "    print(f\"Running cmd {cmd}\")\n",
    "    out = run_command(cmd,f'baseline_{index}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "    index+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x18c3b1093c8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = 'EvaluatePrequentialRegression -l (rules.functions.TargetMean) -s (ArffFileStream -f C:\\\\Users\\\\kosma\\\\Desktop\\\\MAGISTER\\\\FeatExtream\\\\data\\\\airlines.arff ) -i 32000 -f 1000 -q 1000 -d runs/tuning/airlines/rules.functions.TargetMean'\n",
    "\n",
    "run_command(cmd,f'test_airlines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\wisdm.arff'\n",
    "task = 'EvaluatePrequential'\n",
    "learner = 'BufferLearner'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'(meta.AdaptiveRandomForest -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "stream = f'(ArffFileStream -f {file})'\n",
    "\n",
    "\n",
    "w = 200\n",
    "i = 5400\n",
    "f = 200\n",
    "q = 200\n",
    "def generate_command(n, extractor , cluster_num, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}wisdm_{extractor}_{n}_{cluster_num}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -e (WindowClassificationPerformanceEvaluator -w {w}) -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p -1 -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EvaluatePrequential -l (BufferLearner -l (meta.AdaptiveRandomForest -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01)) -n 10 -m (meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01)) -c cluster -r 1 -b random -p -1 -q clustree -x 8) -s (ArffFileStream -f C:/Users/kosma/Desktop/MAGISTER/FeatExtream/data/wisdm.arff) -e (WindowClassificationPerformanceEvaluator -w 200) -i 5400 -f 200 -q 200 -d runs/tuning/wisdm/buffer/wisdm_cluster_10_8_clustree_random_100.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_command(10, 'cluster', 8, 'clustree', target_dir = 'wisdm/buffer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n",
      "Running with n = 50\n",
      "Running with n = 100\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [1,5,10,25,50,100]:\n",
    "    cmd = generate_command(n, 'cluster', 8, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'wisdm_cluster_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 5\n",
      "Running with n = 10\n",
      "Running with n = 25\n",
      "Running with n = 50\n",
      "Running with n = 100\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [1,5,10,25,50,100]:\n",
    "    cmd = generate_command(n, 'cep', 8, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'wisdm_cep_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 2\n",
      "Running with c = 3\n",
      "Running with c = 4\n",
      "Running with c = 6\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for c in [3,4,6]:\n",
    "    cmd = generate_command(1, 'cep', c, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_cep_c{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "for c in [3,4,6]:\n",
    "    cmd = generate_command(1, 'cep', c, 'clustream', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_cep_c{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<subprocess.Popen at 0x2162ecc7860>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_command(cmd,f'tss_{1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 4\n",
      "Running with c = 6\n",
      "Running with c = 4\n",
      "Running with c = 6\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for c in [4,6]:\n",
    "    cmd = generate_command(1, 'cluster', c, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_cluster_c{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "for c in [4,6]:\n",
    "    cmd = generate_command(1, 'cluster', c, 'clustream', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_cluster_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with c = 4\n",
      "Running with c = 6\n",
      "Running with c = 4\n",
      "Running with c = 6\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for c in [4,6]:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_featureExtraction_c{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "for c in [4,6]:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustream', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_featureExtraction_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustree', buffer_type='relevance', r=r, target_dir = 'wisdm/buffer/')\n",
    "\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'featureExtractionp_r2{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with r = 0.1\n",
      "Running with r = 0.25\n",
      "Running with r = 0.5\n"
     ]
    }
   ],
   "source": [
    "for r in rs:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustree', buffer_type='random', r=r, target_dir = 'wisdm/buffer/')\n",
    "\n",
    "    print(f\"Running with r = {r}\")\n",
    "    out = run_command(cmd,f'featureExtractionp_r{r}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_together = 10\n",
    "for r in [0.1,0.25,0.5]:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustree', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_featureExtraction_c{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()\n",
    "for c in [4,6]:\n",
    "    cmd = generate_command(1, 'featureExtraction', c, 'clustream', target_dir = 'wisdm/buffer/')\n",
    "    print(f\"Running with c = {c}\")\n",
    "    out = run_command(cmd,f'wisdm_featureExtraction_c2{c}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file =  r'C:\\Users\\kosma\\Desktop\\MAGISTER\\FeatExtream\\data\\electricity_arff.arff'\n",
    "task = 'EvaluatePrequential'\n",
    "learner = 'BufferLearner'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'(meta.AdaptiveRandomForest -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "stream = f'(ArffFileStream -f {file})'\n",
    "\n",
    "\n",
    "i = 45000\n",
    "f = 1000\n",
    "q = 1000\n",
    "def generate_command(n, extractor , cluster_num, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}wisdm_{extractor}_{n}_{cluster_num}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p -1 -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 5\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [1,5,10]:\n",
    "    cmd = generate_command(n, 'cluster', 8, 'clustree', target_dir = 'electricity/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'wisdm_cluster_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [1,3,5,10]:\n",
    "    cmd = generate_command(n, 'cep', 4, 'clustream', target_dir = 'electricity/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'wisdm_cep_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 1\n",
      "Running with n = 3\n",
      "Running with n = 5\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [1,3,5, 10]:\n",
    "    cmd = generate_command(n, 'featureExtraction', 4, 'clustream', target_dir = 'electricity/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'wisdm_featureExtraction_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'EvaluatePrequential'\n",
    "learner = 'BufferLearner'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'lazy.SAMkNN'\n",
    "stream = f'generators.RandomRBFGenerator'\n",
    "\n",
    "\n",
    "i = 50000\n",
    "f = 1000\n",
    "q = 1000\n",
    "def generate_command(n, extractor , cluster_num, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}wisdm_{extractor}_{n}_{cluster_num}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p -1 -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [10]:\n",
    "    cmd = generate_command(n, 'featureExtraction', 4, 'clustream', target_dir = 'generated/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'generated_featureExtraction_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [10]:\n",
    "    cmd = generate_command(n, 'cep', 4, 'clustream', target_dir = 'generated/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'generated_cep_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for n in [10]:\n",
    "    cmd = generate_command(n, 'cluster', 6, 'clustree', target_dir = 'generated/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'generated_cluster_n{n}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'EvaluatePrequential'\n",
    "learner = 'BufferLearner'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'meta.OzaBagAdwin'\n",
    "stream = f'generators.HyperplaneGenerator'\n",
    "\n",
    "\n",
    "i = 50000\n",
    "f = 1000\n",
    "q = 1000\n",
    "def generate_command(n, extractor , cluster_num, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}hyperplane_{extractor}_{n}_{cluster_num}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p -1 -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 10\n",
      "Running with n = 10\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for t in ['cluster', 'cep', 'featureExtraction']:\n",
    "    cmd = generate_command(10, t, 6, 'clustree', target_dir = 'generated/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'generated_{t}_n{10}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'EvaluatePrequential'\n",
    "learner = 'BufferLearner'\n",
    "\n",
    "relevance_learner = '(meta.AdaptiveRandomForestRegressor -x (ADWINChangeDetector -a 0.001) -p (ADWINChangeDetector -a 0.01))'\n",
    "buffer_learner = f'meta.OzaBagAdwin'\n",
    "stream = f'generators.LEDGenerator'\n",
    "\n",
    "\n",
    "i = 50000\n",
    "f = 1000\n",
    "q = 1000\n",
    "def generate_command(n, extractor , cluster_num, cluster_type='clustree', buffer_type = 'random', r = 1, target_dir = ''):\n",
    "    pathlib.Path(f'runs/tuning/{target_dir}').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    target_file = f'runs/tuning/{target_dir}led_{extractor}_{n}_{cluster_num}_{cluster_type}_{buffer_type}_{int(r*100)}.csv'\n",
    "    start_cmd = f'{task} -l ({learner} -l {buffer_learner} -n {n} -m {relevance_learner}'\n",
    "    end_cmd = f') -s {stream} -i {i} -f {f} -q {q} -d {target_file}'\n",
    "    cmd = f'{start_cmd} -c {extractor} -r {r} -b {buffer_type} -p -1 -q {cluster_type} -x {cluster_num}{end_cmd}'\n",
    "    cmd = cmd.replace(\"\\\\\",\"/\")\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running with n = 10\n",
      "Running with n = 10\n",
      "Running with n = 10\n"
     ]
    }
   ],
   "source": [
    "max_together = 10\n",
    "for t in ['cluster', 'cep', 'featureExtraction']:\n",
    "    cmd = generate_command(10, t, 6, 'clustree', target_dir = 'generated/buffer/')\n",
    "    print(f\"Running with n = {n}\")\n",
    "    out = run_command(cmd,f'led_{t}_n{10}')\n",
    "    outs.append(out)\n",
    "\n",
    "    if len(outs) >= max_together:\n",
    "        outs[len(outs) - max_together].communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
